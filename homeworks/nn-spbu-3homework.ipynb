{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1614414,"sourceType":"datasetVersion","datasetId":953194},{"sourceId":2780478,"sourceType":"datasetVersion","datasetId":1697417},{"sourceId":14178459,"sourceType":"datasetVersion","datasetId":9038366},{"sourceId":14266168,"sourceType":"datasetVersion","datasetId":9103652},{"sourceId":14284900,"sourceType":"datasetVersion","datasetId":9117719}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport regex as re\n\nfrom collections import Counter, defaultdict\nfrom statistics import mean\nimport random\nimport os\n\nimport matplotlib.pyplot as plt\n\nimport math\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:50:18.176621Z","iopub.execute_input":"2025-12-24T15:50:18.176878Z","iopub.status.idle":"2025-12-24T15:50:23.263574Z","shell.execute_reply.started":"2025-12-24T15:50:18.176844Z","shell.execute_reply":"2025-12-24T15:50:23.263004Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Задание 1. BPE Токенизатор","metadata":{}},{"cell_type":"code","source":"def get_text(\n    n_samples_train=300,\n    n_samples_test=300,\n    random_state=42\n):\n    data = pd.read_csv('/kaggle/input/19-000-russian-poems/poems.csv')\n    data.dropna(inplace=True)\n\n    rng = random.Random(random_state)\n\n    data_train = data.sample(n=n_samples_train, random_state=random_state)\n    training_text = \"\\n\".join(data_train[\"text\"].tolist())\n\n    remaining = data.drop(data_train.index)\n\n    data_test = remaining.sample(n=n_samples_test, random_state=random_state + 1)\n\n    lines = []\n    for t in data_test[\"text\"]:\n        split_lines = [l.strip() for l in t.split(\"\\n\") if l.strip()]\n        rng.shuffle(split_lines)\n        lines.extend(split_lines)\n\n    rng.shuffle(lines)\n    test_text = \"\\n\".join(lines)\n\n    return training_text, test_text\n\ntraining_text, test_text = get_text()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:37:18.553538Z","iopub.execute_input":"2025-12-24T14:37:18.554037Z","iopub.status.idle":"2025-12-24T14:37:19.319054Z","shell.execute_reply.started":"2025-12-24T14:37:18.554014Z","shell.execute_reply":"2025-12-24T14:37:19.318419Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class MyBPETokenizer:\n    def __init__(self, vocab_size=512):\n        self.vocab_size = vocab_size\n\n        self.pre_tok_pattern = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")\n\n        self.bpe_merges = []\n        self.token_to_id = {}\n        self.id_to_token = {}\n\n        self.eot_token = \"<|endoftext|>\"\n\n\n    def pre_tokenize(self, text):\n        return re.findall(self.pre_tok_pattern, text)\n\n\n    def to_bytes(self, s):\n        return [chr(b) for b in s.encode(\"utf-8\")]\n\n    def from_bytes(self, symbols):\n        byte_array = bytearray()\n        for s in symbols:\n            byte_array.extend(ord(c) for c in s)\n        return byte_array.decode(\"utf-8\", errors=\"replace\")\n\n    def train(self, text):\n        pre_tokens = self.pre_tokenize(text)\n    \n        corpus = [self.to_bytes(tok) for tok in pre_tokens]\n    \n        vocab = {chr(i) for i in range(256)}\n    \n        while len(vocab) < self.vocab_size:\n            pair_freq = Counter()\n    \n            for word in corpus:\n                for i in range(len(word) - 1):\n                    pair_freq[(word[i], word[i + 1])] += 1\n    \n            if not pair_freq:\n                break\n    \n            best_pair = pair_freq.most_common(1)[0][0]\n            self.bpe_merges.append(best_pair)\n    \n            new_symbol = \"\".join(best_pair)\n    \n            new_corpus = []\n            for word in corpus:\n                new_word = []\n                i = 0\n                while i < len(word):\n                    if i < len(word) - 1 and (word[i], word[i + 1]) == best_pair:\n                        new_word.append(new_symbol)\n                        i += 2\n                    else:\n                        new_word.append(word[i])\n                        i += 1\n                new_corpus.append(new_word)\n    \n            corpus = new_corpus\n            vocab.add(new_symbol)\n    \n        vocab = sorted(vocab)\n        vocab.append(self.eot_token)\n    \n        self.token_to_id = {tok: i for i, tok in enumerate(vocab)}\n        self.id_to_token = {i: tok for tok, i in self.token_to_id.items()}\n\n\n\n    def encode(self, text, add_eot=False):\n        tokens = []\n    \n        if add_eot:\n            tokens.append(self.token_to_id[self.eot_token])\n    \n        pre_tokens = self.pre_tokenize(text)\n    \n        for tok in pre_tokens:\n            symbols = self.to_bytes(tok)\n    \n            for merge in self.bpe_merges:\n                i = 0\n                new_symbols = []\n                while i < len(symbols):\n                    if i < len(symbols) - 1 and (symbols[i], symbols[i + 1]) == merge:\n                        new_symbols.append(\"\".join(merge))\n                        i += 2\n                    else:\n                        new_symbols.append(symbols[i])\n                        i += 1\n                symbols = new_symbols\n    \n            tokens.extend(self.token_to_id[s] for s in symbols)\n    \n        return tokens\n\n\n    def decode(self, token_ids, skip_eot=True):\n        symbols = []\n    \n        for i in token_ids:\n            tok = self.id_to_token[i]\n            if skip_eot and tok == self.eot_token:\n                continue\n            symbols.append(tok)\n    \n        return self.from_bytes(symbols)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:37:19.320340Z","iopub.execute_input":"2025-12-24T14:37:19.320712Z","iopub.status.idle":"2025-12-24T14:37:19.332461Z","shell.execute_reply.started":"2025-12-24T14:37:19.320687Z","shell.execute_reply":"2025-12-24T14:37:19.331861Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"tokenizer = MyBPETokenizer()\n\ntokenizer.train(training_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:37:21.207702Z","iopub.execute_input":"2025-12-24T14:37:21.208325Z","iopub.status.idle":"2025-12-24T14:37:55.199093Z","shell.execute_reply.started":"2025-12-24T14:37:21.208301Z","shell.execute_reply":"2025-12-24T14:37:55.198501Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### Метрики","metadata":{}},{"cell_type":"code","source":"WORD_RE = re.compile(r\"\\p{L}+|\\p{N}+\")\n\ndef tokenizer_stats(tokenizer, text):\n    token_ids = tokenizer.encode(text)\n    num_tokens = len(token_ids)\n\n    num_bytes = len(text.encode(\"utf-8\"))\n    num_chars = len(text)\n\n    compression = {\n        \"tokens_per_byte\": num_tokens / num_bytes if num_bytes else 0.0,\n        \"tokens_per_char\": num_tokens / num_chars if num_chars else 0.0,\n    }\n\n    words = re.findall(WORD_RE, text)\n    if not words:\n        return {\n            **compression,\n            \"avg_tokens_per_word\": 0.0,\n            \"avg_tokens_per_word_top_10pct\": 0.0,\n        }\n\n    tokens_per_word = []\n    for w in words:\n        tokens_per_word.append(len(tokenizer.encode(w)))\n\n    avg_tokens_per_word = mean(tokens_per_word)\n\n    freq = Counter(words)\n    unique_words = list(freq.keys())\n    unique_words.sort(key=lambda w: freq[w], reverse=True)\n\n    top_k = max(1, int(0.1 * len(unique_words)))\n    top_words = set(unique_words[:top_k])\n\n    top_tokens_per_word = [\n        len(tokenizer.encode(w))\n        for w in words\n        if w in top_words\n    ]\n\n    avg_tokens_top = mean(top_tokens_per_word) if top_tokens_per_word else 0.0\n\n    return {\n        **compression,\n        \"avg_tokens_per_word\": avg_tokens_per_word,\n        \"avg_tokens_per_word_top_10pct\": avg_tokens_top,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:37:55.200175Z","iopub.execute_input":"2025-12-24T14:37:55.200433Z","iopub.status.idle":"2025-12-24T14:37:55.207152Z","shell.execute_reply.started":"2025-12-24T14:37:55.200416Z","shell.execute_reply":"2025-12-24T14:37:55.206625Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"Проверим на художественном тексте:","metadata":{}},{"cell_type":"code","source":"stats = tokenizer_stats(tokenizer, test_text)\n\nfor k, v in stats.items():\n    print(f\"{k}: {v:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T10:09:23.323584Z","iopub.execute_input":"2025-12-23T10:09:23.323902Z","iopub.status.idle":"2025-12-23T10:09:48.074516Z","shell.execute_reply.started":"2025-12-23T10:09:23.323876Z","shell.execute_reply":"2025-12-23T10:09:48.073619Z"}},"outputs":[{"name":"stdout","text":"tokens_per_byte: 0.3437\ntokens_per_char: 0.6174\navg_tokens_per_word: 3.3294\navg_tokens_per_word_top_10pct: 2.3928\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"На новостном:","metadata":{}},{"cell_type":"code","source":"news_text = \"\"\"Следователи отдела полиции Томска возбудили уголовное дело по факту умышленного поджога в гипермаркете «Лента», который загорелся 25 декабря. Подозреваемый задержан, ему предъявлено обвинение, сообщает «МВД медиа».\nЭто уже второй пожар в «Ленте» за неделю — 21 декабря горело здание гипермаркета на улице Елизаровых, а вчера вспыхнуло помещение ТЦ на улице Пушкина. Пожар произошел в отделе по продаже пиротехнических изделий и охватил площадь 20 кв. м. Из здания эвакуировались около 500 посетителей и около 150 человек персонала, сообщало региональное МЧС.\nПолицейские установили личность совершившего поджог мужчины, задержали его «по горячим следам». 27-летний житель Томска «взял с прилавка легковоспламеняющуюся жидкость и газовую горелку, после чего облил горючей смесью пиротехнические изделия», рассказали в полиции.\nУголовное дело возбуждено по факту умышленного уничтожения или повреждения имущества (ч. 3 ст. 30, ч. 2 ст. 167 УК РФ), мужчине предъявлено обвинение.\nПервое возгорание в «Ленте» произошло на площади 5000 кв. м. По данным ТАСС, оно началось с поддонов в секции непродовольственных товаров. В результате у гипермаркета обрушилась кровля. Тогда поджог устроил сотрудник подрядной организации гипермаркета, работавший в торговом зале. Ранее он уже привлекался к уголовной ответственности, сообщали «РИА Новости».\n\"\"\"\n\nstats = tokenizer_stats(tokenizer, news_text)\n\nfor k, v in stats.items():\n    print(f\"{k}: {v:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T10:09:48.075914Z","iopub.execute_input":"2025-12-23T10:09:48.076191Z","iopub.status.idle":"2025-12-23T10:09:48.190384Z","shell.execute_reply.started":"2025-12-23T10:09:48.076167Z","shell.execute_reply":"2025-12-23T10:09:48.189556Z"}},"outputs":[{"name":"stdout","text":"tokens_per_byte: 0.3501\ntokens_per_char: 0.6370\navg_tokens_per_word: 4.2857\navg_tokens_per_word_top_10pct: 3.7895\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"На официальном:","metadata":{}},{"cell_type":"code","source":"official_text = \"Статья посвящена исследованию устойчивых выражений (клише), употребляемых в современных законах и модельных законодательных актах. Разграничиваются понятия «законодательное клише» и «речевой штамп». Обосновываются основные подходы к исследованию (дискурсивный и жанрово-стилистический), их корреляция. Рассматриваются разновидности законодательных клише (общеотраслевые, межотраслевые, отраслевые, акционально-императивные, рамочно-отсылочные), их функции и иные особенности. Во-первых, сообщение информации, универсальной для правового регулирования общественных отношений (общеотраслевые, межотраслевые клише). Во-вторых, идентификация конкретной области регулируемых отношений (отраслевые клише). В-третьих, обозначение действий, которые совершаются по отношению к законодательным понятиям, структурным единицам или законодательному тексту в целом (акционально-императивные клише). В-четвертых, обозначение структурных единиц закона, а также способов отсылок к тексту закона или его части (рамочно-отсылочные клише). Выделяются общие признаки законодательных клише: целостность значения, семантическая устойчивость, унифицированность структуры, контекстуальная устойчивость (локальность), регулярность воспроизводства, полифункциональность. Определяются потенциальные (дополнительные) признаки: трансформация значения, дополнение компонентами (расширение семантики), вариативность употребления, эквивалентность (возможность замещения), но не тождественность. Делается вывод о том, что законодательное клише является дискурсивным маркером речевого жанра «Закон». Материал исследования: тексты федеральных законов и модельных актов, словари законодательных терминов.\"\n\nstats = tokenizer_stats(tokenizer, official_text)\n\nfor k, v in stats.items():\n    print(f\"{k}: {v:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T10:09:48.191153Z","iopub.execute_input":"2025-12-23T10:09:48.191432Z","iopub.status.idle":"2025-12-23T10:09:48.337981Z","shell.execute_reply.started":"2025-12-23T10:09:48.191402Z","shell.execute_reply":"2025-12-23T10:09:48.336917Z"}},"outputs":[{"name":"stdout","text":"tokens_per_byte: 0.3279\ntokens_per_char: 0.6101\navg_tokens_per_word: 5.3964\navg_tokens_per_word_top_10pct: 4.6667\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"Эффективность токенизатора существенно зависит от домена. <br>\nХотя коэффициент сжатия по байтам остаётся относительно стабильным, среднее число токенов на слово и особенно для частотных слов резко возрастает при переходе от художественного текста к новостному и официальному, что указывает на ухудшение покрытия лексического ядра домена.","metadata":{}},{"cell_type":"markdown","source":"### Кривая размер словаря vs compression ratio","metadata":{}},{"cell_type":"code","source":"def compression_ratio(tokenizer, text):\n    token_ids = tokenizer.encode(text)\n    num_tokens = len(token_ids)\n    num_bytes = len(text.encode(\"utf-8\"))\n    return num_tokens / num_bytes\n\ndef vocab_vs_compression_curve(\n    tokenizer_class,\n    training_text,\n    eval_text,\n    vocab_sizes\n):\n    results = []\n\n    for vs in vocab_sizes:\n        tok = tokenizer_class(vocab_size=vs)\n        tok.train(training_text)\n\n        cr = compression_ratio(tok, eval_text)\n\n        results.append({\n            \"vocab_size\": vs,\n            \"compression_ratio\": cr\n        })\n\n        print(f\"vocab={vs:6d} | compression={cr:.4f}\")\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T07:51:41.259326Z","iopub.execute_input":"2025-12-23T07:51:41.259653Z","iopub.status.idle":"2025-12-23T07:51:41.265941Z","shell.execute_reply.started":"2025-12-23T07:51:41.259630Z","shell.execute_reply":"2025-12-23T07:51:41.264908Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"vocab_sizes = [\n    256,\n    512,\n    1_000,\n    2_000,\n    4_000\n]\n\ncurve = vocab_vs_compression_curve(\n    MyBPETokenizer,\n    training_text,\n    test_text,\n    vocab_sizes\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T08:09:11.050717Z","iopub.execute_input":"2025-12-23T08:09:11.051100Z","iopub.status.idle":"2025-12-23T08:26:31.298758Z","shell.execute_reply.started":"2025-12-23T08:09:11.051073Z","shell.execute_reply":"2025-12-23T08:26:31.297980Z"}},"outputs":[{"name":"stdout","text":"vocab=   256 | compression=1.0000\nvocab=   512 | compression=0.3437\nvocab=  1000 | compression=0.2809\nvocab=  2000 | compression=0.2456\nvocab=  4000 | compression=0.2220\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"xs = [p[\"vocab_size\"] for p in curve]\nys = [p[\"compression_ratio\"] for p in curve]\n\nplt.figure(figsize=(8, 5))\nplt.plot(xs, ys, marker=\"o\")\nplt.xscale(\"log\")\nplt.xlabel(\"Vocabulary size (log scale)\")\nplt.ylabel(\"Tokens per byte (compression ratio)\")\nplt.title(\"BPE Vocabulary Size vs Compression Ratio\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T08:29:10.468465Z","iopub.execute_input":"2025-12-23T08:29:10.469390Z","iopub.status.idle":"2025-12-23T08:29:10.912098Z","shell.execute_reply.started":"2025-12-23T08:29:10.469356Z","shell.execute_reply":"2025-12-23T08:29:10.911163Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x500 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":71},{"cell_type":"markdown","source":"### Корпус стихотворений Пушкина","metadata":{}},{"cell_type":"code","source":"def load_texts_from_folder(folder_path, encoding=\"utf-8\"):\n    texts = []\n\n    for fname in os.listdir(folder_path):\n        if fname.endswith(\".txt\"):\n            file_path = os.path.join(folder_path, fname)\n            with open(file_path, \"r\", encoding=encoding) as f:\n                texts.append(f.read())\n\n    return \"\\n\".join(texts)\n\ntext_pushkin = load_texts_from_folder(\"/kaggle/input/pushkin-poetry/texts\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T10:10:50.925285Z","iopub.execute_input":"2025-12-23T10:10:50.926094Z","iopub.status.idle":"2025-12-23T10:10:56.289868Z","shell.execute_reply.started":"2025-12-23T10:10:50.926066Z","shell.execute_reply":"2025-12-23T10:10:56.288736Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def unused_tokens_stats(tokenizer, text):\n    token_ids = tokenizer.encode(text)\n\n    used_token_ids = set(token_ids)\n    all_token_ids = set(tokenizer.id_to_token.keys())\n\n    unused_token_ids = all_token_ids - used_token_ids\n\n    return {\n        \"vocab_size\": len(all_token_ids),\n        \"used_tokens\": len(used_token_ids),\n        \"unused_tokens\": len(unused_token_ids),\n        \"unused_fraction\": len(unused_token_ids) / len(all_token_ids),\n        \"unused_token_ids\": unused_token_ids\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T10:10:56.291396Z","iopub.execute_input":"2025-12-23T10:10:56.291811Z","iopub.status.idle":"2025-12-23T10:10:56.297646Z","shell.execute_reply.started":"2025-12-23T10:10:56.291777Z","shell.execute_reply":"2025-12-23T10:10:56.296669Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"stats = unused_tokens_stats(tokenizer, text_pushkin)\n\nprint(f\"Vocab size: {stats['vocab_size']}\")\nprint(f\"Used tokens: {stats['used_tokens']}\")\nprint(f\"Unused tokens: {stats['unused_tokens']}\")\nprint(f\"Unused fraction: {stats['unused_fraction']:.2%}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T10:10:56.298593Z","iopub.execute_input":"2025-12-23T10:10:56.300578Z","iopub.status.idle":"2025-12-23T10:11:23.449021Z","shell.execute_reply.started":"2025-12-23T10:10:56.300536Z","shell.execute_reply":"2025-12-23T10:11:23.448269Z"}},"outputs":[{"name":"stdout","text":"Vocab size: 513\nUsed tokens: 366\nUnused tokens: 147\nUnused fraction: 28.65%\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def decode_tokens(tokenizer, token_ids):\n    return [tokenizer.id_to_token[i] for i in token_ids]\n\nunused_tokens = decode_tokens(tokenizer, stats[\"unused_token_ids\"])\nunused_tokens[:20]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T10:11:23.450374Z","iopub.execute_input":"2025-12-23T10:11:23.450611Z","iopub.status.idle":"2025-12-23T10:11:23.456845Z","shell.execute_reply.started":"2025-12-23T10:11:23.450592Z","shell.execute_reply":"2025-12-23T10:11:23.455885Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"['\\x00',\n '\\x01',\n '\\x02',\n '\\x03',\n '\\x04',\n '\\x05',\n '\\x06',\n '\\x07',\n '\\x08',\n '\\t',\n '\\nâ\\x80\\x83â\\x80\\x83',\n '\\x0b',\n '\\x0c',\n '\\r',\n '\\x0e',\n '\\x0f',\n '\\x10',\n '\\x11',\n '\\x12',\n '\\x13']"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"## Задача 1.1 Обучение модели","metadata":{}},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, token_ids, block_size):\n        self.data = token_ids\n        self.block_size = block_size\n\n    def __len__(self):\n        return len(self.data) - self.block_size\n\n    def __getitem__(self, idx):\n        x = torch.tensor(self.data[idx:idx+self.block_size], dtype=torch.long)\n        y = torch.tensor(self.data[idx+1:idx+self.block_size+1], dtype=torch.long)\n        return x, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:37:55.207850Z","iopub.execute_input":"2025-12-24T14:37:55.208087Z","iopub.status.idle":"2025-12-24T14:37:55.232494Z","shell.execute_reply.started":"2025-12-24T14:37:55.208061Z","shell.execute_reply":"2025-12-24T14:37:55.231792Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class RNNLM(nn.Module):\n    def __init__(self, vocab_size, embed_dim=256, hidden_dim=512, num_layers=2):\n        super().__init__()\n        self.embed = nn.Embedding(vocab_size, embed_dim)\n        self.rnn = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n        self.head = nn.Linear(hidden_dim, vocab_size)\n\n    def forward(self, x, hidden=None):\n        x = self.embed(x)\n        out, hidden = self.rnn(x, hidden)\n        logits = self.head(out)\n        return logits, hidden\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:37:55.233956Z","iopub.execute_input":"2025-12-24T14:37:55.234159Z","iopub.status.idle":"2025-12-24T14:37:55.246124Z","shell.execute_reply.started":"2025-12-24T14:37:55.234144Z","shell.execute_reply":"2025-12-24T14:37:55.245444Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def build_training_ids(tokenizer, texts):\n    ids = []\n    eot = tokenizer.token_to_id[tokenizer.eot_token]\n\n    for t in texts:\n        ids.append(eot)\n        ids.extend(tokenizer.encode(t))\n\n    return ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:37:55.246947Z","iopub.execute_input":"2025-12-24T14:37:55.247169Z","iopub.status.idle":"2025-12-24T14:37:55.268059Z","shell.execute_reply.started":"2025-12-24T14:37:55.247153Z","shell.execute_reply":"2025-12-24T14:37:55.267413Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def train(model, dataloader, optimizer, device, epochs=5):\n    model.train()\n    loss_fn = nn.CrossEntropyLoss()\n\n    for epoch in range(epochs):\n        total_loss = 0\n        for x, y in dataloader:\n            x = x.to(device)\n            y = y.to(device)\n\n            optimizer.zero_grad()\n            logits, _ = model(x)\n            loss = loss_fn(logits.view(-1, logits.size(-1)), y.view(-1))\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n        print(f\"Epoch {epoch+1}: loss={total_loss/len(dataloader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:37:55.268884Z","iopub.execute_input":"2025-12-24T14:37:55.269130Z","iopub.status.idle":"2025-12-24T14:37:55.284813Z","shell.execute_reply.started":"2025-12-24T14:37:55.269108Z","shell.execute_reply":"2025-12-24T14:37:55.284086Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"@torch.no_grad()\ndef generate(model, tokenizer, max_new_tokens=100, device=\"cpu\"):\n    model.eval()\n    eot_id = tokenizer.token_to_id[tokenizer.eot_token]\n\n    idx = torch.tensor([[eot_id]], device=device)\n    hidden = None\n\n    for _ in range(max_new_tokens):\n        logits, hidden = model(idx[:, -1:].to(device), hidden)\n        probs = torch.softmax(logits[:, -1, :], dim=-1)\n        next_id = torch.multinomial(probs, num_samples=1)\n        idx = torch.cat([idx, next_id], dim=1)\n        if next_id.item() == eot_id:\n            break\n\n    return tokenizer.decode(idx[0].tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:37:55.285611Z","iopub.execute_input":"2025-12-24T14:37:55.286571Z","iopub.status.idle":"2025-12-24T14:37:55.301499Z","shell.execute_reply.started":"2025-12-24T14:37:55.286547Z","shell.execute_reply":"2025-12-24T14:37:55.301042Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/19-000-russian-poems/poems.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:37:55.302126Z","iopub.execute_input":"2025-12-24T14:37:55.302328Z","iopub.status.idle":"2025-12-24T14:37:56.005610Z","shell.execute_reply.started":"2025-12-24T14:37:55.302313Z","shell.execute_reply":"2025-12-24T14:37:56.004784Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"data.dropna(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:37:56.006599Z","iopub.execute_input":"2025-12-24T14:37:56.006854Z","iopub.status.idle":"2025-12-24T14:37:56.015440Z","shell.execute_reply.started":"2025-12-24T14:37:56.006828Z","shell.execute_reply":"2025-12-24T14:37:56.014657Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:37:56.017385Z","iopub.execute_input":"2025-12-24T14:37:56.017561Z","iopub.status.idle":"2025-12-24T14:37:56.044281Z","shell.execute_reply.started":"2025-12-24T14:37:56.017547Z","shell.execute_reply":"2025-12-24T14:37:56.043550Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                     writer                                       poem  \\\n1  Лермонтов Михаил Юрьевич                       На серебряные шпоры…   \n2  Лермонтов Михаил Юрьевич                  Вид гор из степей Козлова   \n3  Лермонтов Михаил Юрьевич     К  (О, не скрывай! Ты плакала об нем…)   \n4  Лермонтов Михаил Юрьевич  Жалобы турка (письмо к другу, иностранцу)   \n5  Лермонтов Михаил Юрьевич                              К кн. Л. Г-ой   \n\n                                                text  \n1  На серебряные шпоры\\nЯ в раздумии гляжу;\\nЗа т...  \n2  Пилигрим\\nАллах ли там среди пустыни\\nЗастывши...  \n3  О, не скрывай! Ты плакала об нем –\\nИ я его лю...  \n4  Ты знал ли дикий край, под знойными лучами,\\nГ...  \n5  Когда ты холодно внимаешь\\nРассказам горести ч...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>writer</th>\n      <th>poem</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Лермонтов Михаил Юрьевич</td>\n      <td>На серебряные шпоры…</td>\n      <td>На серебряные шпоры\\nЯ в раздумии гляжу;\\nЗа т...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Лермонтов Михаил Юрьевич</td>\n      <td>Вид гор из степей Козлова</td>\n      <td>Пилигрим\\nАллах ли там среди пустыни\\nЗастывши...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Лермонтов Михаил Юрьевич</td>\n      <td>К  (О, не скрывай! Ты плакала об нем…)</td>\n      <td>О, не скрывай! Ты плакала об нем –\\nИ я его лю...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Лермонтов Михаил Юрьевич</td>\n      <td>Жалобы турка (письмо к другу, иностранцу)</td>\n      <td>Ты знал ли дикий край, под знойными лучами,\\nГ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Лермонтов Михаил Юрьевич</td>\n      <td>К кн. Л. Г-ой</td>\n      <td>Когда ты холодно внимаешь\\nРассказам горести ч...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"texts = data.sample(n=50, random_state=1)['text'].to_list()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:37:56.045094Z","iopub.execute_input":"2025-12-24T14:37:56.045547Z","iopub.status.idle":"2025-12-24T14:37:56.054431Z","shell.execute_reply.started":"2025-12-24T14:37:56.045531Z","shell.execute_reply":"2025-12-24T14:37:56.053739Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"token_ids = build_training_ids(tokenizer, texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:37:56.055268Z","iopub.execute_input":"2025-12-24T14:37:56.056104Z","iopub.status.idle":"2025-12-24T14:38:01.221515Z","shell.execute_reply.started":"2025-12-24T14:37:56.056087Z","shell.execute_reply":"2025-12-24T14:38:01.220920Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"dataset = MyDataset(token_ids, block_size=128)\nloader = DataLoader(dataset, batch_size=64, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:38:01.222215Z","iopub.execute_input":"2025-12-24T14:38:01.222419Z","iopub.status.idle":"2025-12-24T14:38:01.226969Z","shell.execute_reply.started":"2025-12-24T14:38:01.222402Z","shell.execute_reply":"2025-12-24T14:38:01.226233Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"len(loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:38:01.227603Z","iopub.execute_input":"2025-12-24T14:38:01.227839Z","iopub.status.idle":"2025-12-24T14:38:01.241172Z","shell.execute_reply.started":"2025-12-24T14:38:01.227823Z","shell.execute_reply":"2025-12-24T14:38:01.240630Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"1603"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = RNNLM(\n    vocab_size=len(tokenizer.token_to_id),\n    embed_dim=256,\n    hidden_dim=512,\n    num_layers=2\n).to(device)\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n\ntrain(model, loader, optimizer, device, epochs=5)\n\nprint(generate(model, tokenizer, max_new_tokens=200, device=device))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:38:01.241893Z","iopub.execute_input":"2025-12-24T14:38:01.242486Z","iopub.status.idle":"2025-12-24T14:47:44.771909Z","shell.execute_reply.started":"2025-12-24T14:38:01.242464Z","shell.execute_reply":"2025-12-24T14:47:44.771058Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: loss=2.8153\nEpoch 2: loss=0.8784\nEpoch 3: loss=0.2739\nEpoch 4: loss=0.1704\nEpoch 5: loss=0.1359\nБывало, великий гнев государь\nЕсли вы? �а его запасно ты…\nЗоловника: ль з чуга дорог\nЗдесью за ль, на бояри\nНин кинчалек, молча, от и звены и пол от наро\nЗаговлишивена алите:\nНаврием заруя\n      ин Думя знаем\nМофутом по смолский смирят,\nЧеробный крест, котору вздавь\nОт тебе переживе твоей!\nШ у й с к и й\n(крыливо)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"@torch.no_grad()\ndef generate_with_context(\n    model,\n    tokenizer,\n    prompt,\n    max_new_tokens=200,\n    temperature=1.0,\n    device=\"cpu\"\n):\n    model.eval()\n\n    context_ids = tokenizer.encode(prompt, add_eot=False)\n    idx = torch.tensor(context_ids, dtype=torch.long, device=device).unsqueeze(0)\n\n    hidden = None\n\n    for i in range(idx.size(1)):\n        _, hidden = model(idx[:, i:i+1], hidden)\n\n    generated = idx\n\n    for _ in range(max_new_tokens):\n        logits, hidden = model(generated[:, -1:], hidden)\n        logits = logits[:, -1, :] / temperature\n        probs = torch.softmax(logits, dim=-1)\n\n        next_id = torch.multinomial(probs, num_samples=1)\n        generated = torch.cat([generated, next_id], dim=1)\n\n        if next_id.item() == tokenizer.token_to_id[tokenizer.eot_token]:\n            break\n\n    return tokenizer.decode(generated[0].tolist())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:47:50.983151Z","iopub.execute_input":"2025-12-24T14:47:50.983851Z","iopub.status.idle":"2025-12-24T14:47:50.990832Z","shell.execute_reply.started":"2025-12-24T14:47:50.983829Z","shell.execute_reply":"2025-12-24T14:47:50.990240Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"print(\n    generate_with_context(\n        model,\n        tokenizer,\n        prompt=\"У лукоморья дуб зеленый\",\n        max_new_tokens=200,\n        temperature=0.8,\n        device=device\n    )\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:47:53.169311Z","iopub.execute_input":"2025-12-24T14:47:53.169566Z","iopub.status.idle":"2025-12-24T14:47:53.300929Z","shell.execute_reply.started":"2025-12-24T14:47:53.169547Z","shell.execute_reply":"2025-12-24T14:47:53.300167Z"}},"outputs":[{"name":"stdout","text":"У лукоморья дуб зеленый,\nИ в глубокой так гручкий бы.\nСя ж жизнь, убитом, боярин;\nУше зороде,\nТак и голович не кресто сами, она — чему\nЗабудескому долго\nХотите ль выйти на смотреть! стрелно!\nГ о л и с\nПон в а р о я,\nМ и х а р и ц а И р и н а,\nПилуй смеликий говорю,\nДа приходи помилоси! Там бытьцы мы путо его.\nБез покаая там!\nГ о д у н о в\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## Задание 1.2. Дообучение GPT-2","metadata":{}},{"cell_type":"code","source":"class GPT2Dataset(Dataset):\n    def __init__(self, token_ids, seq_len=256):\n        self.data = torch.tensor(token_ids, dtype=torch.long)\n        self.seq_len = seq_len\n\n    def __len__(self):\n        return len(self.data) - self.seq_len\n\n    def __getitem__(self, idx):\n        chunk = self.data[idx : idx + self.seq_len + 1]\n        x = chunk[:-1]\n        y = chunk[1:]\n        return x, y\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:48:00.834636Z","iopub.execute_input":"2025-12-24T14:48:00.835133Z","iopub.status.idle":"2025-12-24T14:48:00.840127Z","shell.execute_reply.started":"2025-12-24T14:48:00.835112Z","shell.execute_reply":"2025-12-24T14:48:00.839420Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def adapt_gpt2(model, new_vocab_size):\n    old_vocab_size = model.config.vocab_size\n    hidden_dim = model.config.n_embd\n\n    old_emb = model.transformer.wte.weight.data\n    old_head = model.lm_head.weight.data\n\n    new_emb = nn.Embedding(new_vocab_size, hidden_dim)\n    new_head = nn.Linear(hidden_dim, new_vocab_size, bias=False)\n\n    n = min(old_vocab_size, new_vocab_size)\n    new_emb.weight.data[:n] = old_emb[:n]\n    new_head.weight.data[:n] = old_head[:n]\n\n    if new_vocab_size > old_vocab_size:\n        nn.init.normal_(new_emb.weight.data[n:], std=0.02)\n        nn.init.normal_(new_head.weight.data[n:], std=0.02)\n\n    model.transformer.wte = new_emb\n    model.lm_head = new_head\n    model.config.vocab_size = new_vocab_size\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:48:04.190853Z","iopub.execute_input":"2025-12-24T14:48:04.191459Z","iopub.status.idle":"2025-12-24T14:48:04.196824Z","shell.execute_reply.started":"2025-12-24T14:48:04.191437Z","shell.execute_reply":"2025-12-24T14:48:04.196032Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from torch.cuda.amp import autocast, GradScaler\n\ndef train_gpt2(\n    model,\n    dataloader,\n    device,\n    epochs=3,\n    lr=5e-5\n):\n    model.train()\n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=lr,\n        weight_decay=0.01\n    )\n    scaler = GradScaler()\n\n    for epoch in range(epochs):\n        total_loss = 0.0\n\n        for step, (x, y) in enumerate(dataloader):\n            x = x.to(device)\n            y = y.to(device)\n\n            optimizer.zero_grad()\n\n            with torch.autocast(device_type=\"cuda\"):\n                outputs = model(input_ids=x, labels=y)\n                loss = outputs.loss\n\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            scaler.step(optimizer)\n            scaler.update()\n\n            total_loss += loss.item()\n\n            if step % 50 == 0:\n                print(\n                    f\"Epoch {epoch+1} | Step {step} | Loss {loss.item():.4f}\"\n                )\n\n        print(\n            f\"Epoch {epoch+1} finished | Avg loss {total_loss/len(dataloader):.4f}\\n\"\n        )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:48:08.776838Z","iopub.execute_input":"2025-12-24T14:48:08.777150Z","iopub.status.idle":"2025-12-24T14:48:08.783583Z","shell.execute_reply.started":"2025-12-24T14:48:08.777132Z","shell.execute_reply":"2025-12-24T14:48:08.782870Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from transformers import GPT2LMHeadModel\nfrom torch.utils.data import DataLoader\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n\n\nmodel = adapt_gpt2(\n    model,\n    new_vocab_size=len(tokenizer.token_to_id)\n)\n\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:48:43.125343Z","iopub.execute_input":"2025-12-24T14:48:43.125991Z","iopub.status.idle":"2025-12-24T14:48:43.601701Z","shell.execute_reply.started":"2025-12-24T14:48:43.125965Z","shell.execute_reply":"2025-12-24T14:48:43.600867Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(513, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D(nf=2304, nx=768)\n          (c_proj): Conv1D(nf=768, nx=768)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D(nf=3072, nx=768)\n          (c_proj): Conv1D(nf=768, nx=3072)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=513, bias=False)\n)"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"texts = data.sample(n=20, random_state=1)['text'].to_list()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:58:31.442474Z","iopub.execute_input":"2025-12-24T14:58:31.443227Z","iopub.status.idle":"2025-12-24T14:58:31.448952Z","shell.execute_reply.started":"2025-12-24T14:58:31.443197Z","shell.execute_reply":"2025-12-24T14:58:31.447894Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"token_ids = []\nfor text in texts:\n    token_ids.extend(tokenizer.encode(text, add_eot=True))\n\ndataset = GPT2Dataset(token_ids, seq_len=256)\nloader = DataLoader(dataset, batch_size=2, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:58:32.557317Z","iopub.execute_input":"2025-12-24T14:58:32.557932Z","iopub.status.idle":"2025-12-24T14:58:32.952304Z","shell.execute_reply.started":"2025-12-24T14:58:32.557909Z","shell.execute_reply":"2025-12-24T14:58:32.951676Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"train_gpt2(\n    model,\n    loader,\n    device,\n    epochs=3,\n    lr=5e-5\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T14:58:42.441148Z","iopub.execute_input":"2025-12-24T14:58:42.441483Z","iopub.status.idle":"2025-12-24T15:12:08.842808Z","shell.execute_reply.started":"2025-12-24T14:58:42.441462Z","shell.execute_reply":"2025-12-24T15:12:08.841891Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_47/723543046.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Step 0 | Loss 0.3224\nEpoch 1 | Step 50 | Loss 0.1689\nEpoch 1 | Step 100 | Loss 0.2465\nEpoch 1 | Step 150 | Loss 0.1514\nEpoch 1 | Step 200 | Loss 0.1593\nEpoch 1 | Step 250 | Loss 0.0998\nEpoch 1 | Step 300 | Loss 0.1423\nEpoch 1 | Step 350 | Loss 0.0916\nEpoch 1 | Step 400 | Loss 0.0983\nEpoch 1 | Step 450 | Loss 0.1156\nEpoch 1 | Step 500 | Loss 0.1139\nEpoch 1 | Step 550 | Loss 0.1259\nEpoch 1 | Step 600 | Loss 0.1248\nEpoch 1 | Step 650 | Loss 0.0947\nEpoch 1 | Step 700 | Loss 0.0866\nEpoch 1 | Step 750 | Loss 0.0816\nEpoch 1 | Step 800 | Loss 0.0954\nEpoch 1 | Step 850 | Loss 0.0952\nEpoch 1 | Step 900 | Loss 0.0754\nEpoch 1 | Step 950 | Loss 0.0846\nEpoch 1 | Step 1000 | Loss 0.0820\nEpoch 1 | Step 1050 | Loss 0.0955\nEpoch 1 | Step 1100 | Loss 0.0977\nEpoch 1 | Step 1150 | Loss 0.0537\nEpoch 1 | Step 1200 | Loss 0.0759\nEpoch 1 | Step 1250 | Loss 0.0729\nEpoch 1 | Step 1300 | Loss 0.0639\nEpoch 1 | Step 1350 | Loss 0.0795\nEpoch 1 | Step 1400 | Loss 0.0474\nEpoch 1 | Step 1450 | Loss 0.0525\nEpoch 1 | Step 1500 | Loss 0.0777\nEpoch 1 | Step 1550 | Loss 0.0584\nEpoch 1 | Step 1600 | Loss 0.0529\nEpoch 1 | Step 1650 | Loss 0.0814\nEpoch 1 | Step 1700 | Loss 0.0572\nEpoch 1 | Step 1750 | Loss 0.0843\nEpoch 1 | Step 1800 | Loss 0.0598\nEpoch 1 | Step 1850 | Loss 0.0602\nEpoch 1 | Step 1900 | Loss 0.0444\nEpoch 1 | Step 1950 | Loss 0.0789\nEpoch 1 | Step 2000 | Loss 0.0633\nEpoch 1 | Step 2050 | Loss 0.0865\nEpoch 1 | Step 2100 | Loss 0.0414\nEpoch 1 | Step 2150 | Loss 0.0528\nEpoch 1 | Step 2200 | Loss 0.0379\nEpoch 1 | Step 2250 | Loss 0.0595\nEpoch 1 | Step 2300 | Loss 0.0749\nEpoch 1 | Step 2350 | Loss 0.0560\nEpoch 1 | Step 2400 | Loss 0.0403\nEpoch 1 | Step 2450 | Loss 0.0505\nEpoch 1 | Step 2500 | Loss 0.0552\nEpoch 1 | Step 2550 | Loss 0.0498\nEpoch 1 | Step 2600 | Loss 0.0604\nEpoch 1 | Step 2650 | Loss 0.0733\nEpoch 1 | Step 2700 | Loss 0.0643\nEpoch 1 | Step 2750 | Loss 0.0647\nEpoch 1 | Step 2800 | Loss 0.0501\nEpoch 1 | Step 2850 | Loss 0.0763\nEpoch 1 | Step 2900 | Loss 0.0677\nEpoch 1 | Step 2950 | Loss 0.0445\nEpoch 1 | Step 3000 | Loss 0.0676\nEpoch 1 | Step 3050 | Loss 0.0455\nEpoch 1 | Step 3100 | Loss 0.0594\nEpoch 1 | Step 3150 | Loss 0.0428\nEpoch 1 | Step 3200 | Loss 0.0391\nEpoch 1 | Step 3250 | Loss 0.0619\nEpoch 1 | Step 3300 | Loss 0.0437\nEpoch 1 | Step 3350 | Loss 0.0593\nEpoch 1 finished | Avg loss 0.0841\n\nEpoch 2 | Step 0 | Loss 0.0444\nEpoch 2 | Step 50 | Loss 0.0372\nEpoch 2 | Step 100 | Loss 0.0611\nEpoch 2 | Step 150 | Loss 0.0757\nEpoch 2 | Step 200 | Loss 0.0498\nEpoch 2 | Step 250 | Loss 0.0362\nEpoch 2 | Step 300 | Loss 0.0562\nEpoch 2 | Step 350 | Loss 0.0426\nEpoch 2 | Step 400 | Loss 0.0391\nEpoch 2 | Step 450 | Loss 0.0383\nEpoch 2 | Step 500 | Loss 0.0647\nEpoch 2 | Step 550 | Loss 0.0486\nEpoch 2 | Step 600 | Loss 0.0664\nEpoch 2 | Step 650 | Loss 0.0574\nEpoch 2 | Step 700 | Loss 0.0477\nEpoch 2 | Step 750 | Loss 0.0496\nEpoch 2 | Step 800 | Loss 0.0350\nEpoch 2 | Step 850 | Loss 0.0565\nEpoch 2 | Step 900 | Loss 0.0378\nEpoch 2 | Step 950 | Loss 0.0687\nEpoch 2 | Step 1000 | Loss 0.0425\nEpoch 2 | Step 1050 | Loss 0.0420\nEpoch 2 | Step 1100 | Loss 0.0297\nEpoch 2 | Step 1150 | Loss 0.0468\nEpoch 2 | Step 1200 | Loss 0.0615\nEpoch 2 | Step 1250 | Loss 0.0374\nEpoch 2 | Step 1300 | Loss 0.0287\nEpoch 2 | Step 1350 | Loss 0.0782\nEpoch 2 | Step 1400 | Loss 0.0296\nEpoch 2 | Step 1450 | Loss 0.0340\nEpoch 2 | Step 1500 | Loss 0.0617\nEpoch 2 | Step 1550 | Loss 0.0421\nEpoch 2 | Step 1600 | Loss 0.0415\nEpoch 2 | Step 1650 | Loss 0.0741\nEpoch 2 | Step 1700 | Loss 0.0627\nEpoch 2 | Step 1750 | Loss 0.0476\nEpoch 2 | Step 1800 | Loss 0.0633\nEpoch 2 | Step 1850 | Loss 0.0657\nEpoch 2 | Step 1900 | Loss 0.0399\nEpoch 2 | Step 1950 | Loss 0.0332\nEpoch 2 | Step 2000 | Loss 0.0486\nEpoch 2 | Step 2050 | Loss 0.0591\nEpoch 2 | Step 2100 | Loss 0.0780\nEpoch 2 | Step 2150 | Loss 0.0606\nEpoch 2 | Step 2200 | Loss 0.0503\nEpoch 2 | Step 2250 | Loss 0.0587\nEpoch 2 | Step 2300 | Loss 0.0513\nEpoch 2 | Step 2350 | Loss 0.0312\nEpoch 2 | Step 2400 | Loss 0.0761\nEpoch 2 | Step 2450 | Loss 0.0345\nEpoch 2 | Step 2500 | Loss 0.0328\nEpoch 2 | Step 2550 | Loss 0.0356\nEpoch 2 | Step 2600 | Loss 0.0406\nEpoch 2 | Step 2650 | Loss 0.0638\nEpoch 2 | Step 2700 | Loss 0.0553\nEpoch 2 | Step 2750 | Loss 0.0343\nEpoch 2 | Step 2800 | Loss 0.0401\nEpoch 2 | Step 2850 | Loss 0.0446\nEpoch 2 | Step 2900 | Loss 0.0386\nEpoch 2 | Step 2950 | Loss 0.0462\nEpoch 2 | Step 3000 | Loss 0.0430\nEpoch 2 | Step 3050 | Loss 0.0397\nEpoch 2 | Step 3100 | Loss 0.0391\nEpoch 2 | Step 3150 | Loss 0.0550\nEpoch 2 | Step 3200 | Loss 0.0348\nEpoch 2 | Step 3250 | Loss 0.0424\nEpoch 2 | Step 3300 | Loss 0.0499\nEpoch 2 | Step 3350 | Loss 0.0574\nEpoch 2 finished | Avg loss 0.0482\n\nEpoch 3 | Step 0 | Loss 0.0489\nEpoch 3 | Step 50 | Loss 0.0282\nEpoch 3 | Step 100 | Loss 0.0562\nEpoch 3 | Step 150 | Loss 0.0627\nEpoch 3 | Step 200 | Loss 0.0456\nEpoch 3 | Step 250 | Loss 0.0581\nEpoch 3 | Step 300 | Loss 0.0449\nEpoch 3 | Step 350 | Loss 0.0451\nEpoch 3 | Step 400 | Loss 0.0378\nEpoch 3 | Step 450 | Loss 0.0757\nEpoch 3 | Step 500 | Loss 0.0466\nEpoch 3 | Step 550 | Loss 0.0263\nEpoch 3 | Step 600 | Loss 0.0445\nEpoch 3 | Step 650 | Loss 0.0307\nEpoch 3 | Step 700 | Loss 0.0525\nEpoch 3 | Step 750 | Loss 0.0388\nEpoch 3 | Step 800 | Loss 0.0374\nEpoch 3 | Step 850 | Loss 0.0334\nEpoch 3 | Step 900 | Loss 0.0292\nEpoch 3 | Step 950 | Loss 0.0270\nEpoch 3 | Step 1000 | Loss 0.0586\nEpoch 3 | Step 1050 | Loss 0.0412\nEpoch 3 | Step 1100 | Loss 0.0454\nEpoch 3 | Step 1150 | Loss 0.0352\nEpoch 3 | Step 1200 | Loss 0.0493\nEpoch 3 | Step 1250 | Loss 0.0456\nEpoch 3 | Step 1300 | Loss 0.0642\nEpoch 3 | Step 1350 | Loss 0.0383\nEpoch 3 | Step 1400 | Loss 0.0585\nEpoch 3 | Step 1450 | Loss 0.0289\nEpoch 3 | Step 1500 | Loss 0.0199\nEpoch 3 | Step 1550 | Loss 0.0376\nEpoch 3 | Step 1600 | Loss 0.0356\nEpoch 3 | Step 1650 | Loss 0.0347\nEpoch 3 | Step 1700 | Loss 0.0540\nEpoch 3 | Step 1750 | Loss 0.0495\nEpoch 3 | Step 1800 | Loss 0.0542\nEpoch 3 | Step 1850 | Loss 0.0390\nEpoch 3 | Step 1900 | Loss 0.0468\nEpoch 3 | Step 1950 | Loss 0.0378\nEpoch 3 | Step 2000 | Loss 0.0304\nEpoch 3 | Step 2050 | Loss 0.0313\nEpoch 3 | Step 2100 | Loss 0.0360\nEpoch 3 | Step 2150 | Loss 0.0365\nEpoch 3 | Step 2200 | Loss 0.0387\nEpoch 3 | Step 2250 | Loss 0.0423\nEpoch 3 | Step 2300 | Loss 0.0364\nEpoch 3 | Step 2350 | Loss 0.0591\nEpoch 3 | Step 2400 | Loss 0.0548\nEpoch 3 | Step 2450 | Loss 0.0452\nEpoch 3 | Step 2500 | Loss 0.0543\nEpoch 3 | Step 2550 | Loss 0.0369\nEpoch 3 | Step 2600 | Loss 0.0274\nEpoch 3 | Step 2650 | Loss 0.0487\nEpoch 3 | Step 2700 | Loss 0.0371\nEpoch 3 | Step 2750 | Loss 0.0427\nEpoch 3 | Step 2800 | Loss 0.0325\nEpoch 3 | Step 2850 | Loss 0.0260\nEpoch 3 | Step 2900 | Loss 0.0400\nEpoch 3 | Step 2950 | Loss 0.0380\nEpoch 3 | Step 3000 | Loss 0.0356\nEpoch 3 | Step 3050 | Loss 0.0337\nEpoch 3 | Step 3100 | Loss 0.0365\nEpoch 3 | Step 3150 | Loss 0.0551\nEpoch 3 | Step 3200 | Loss 0.0366\nEpoch 3 | Step 3250 | Loss 0.0532\nEpoch 3 | Step 3300 | Loss 0.0345\nEpoch 3 | Step 3350 | Loss 0.0635\nEpoch 3 finished | Avg loss 0.0418\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import torch.nn.functional as F\n\n@torch.no_grad()\ndef generate_gpt2(\n    model,\n    tokenizer,\n    prompt=\"\",\n    max_new_tokens=200,\n    temperature=1.0,\n    top_k=50,\n    device=\"cpu\"\n):\n    model.eval()\n\n\n    input_ids = tokenizer.encode(prompt)\n    input_ids = torch.tensor(input_ids, dtype=torch.long, device=device)\n    input_ids = input_ids.unsqueeze(0)  # [1, T]\n\n    for _ in range(max_new_tokens):\n        outputs = model(input_ids=input_ids)\n        logits = outputs.logits  # [1, T, vocab]\n\n        logits = logits[:, -1, :] / temperature\n\n        # top-k sampling\n        if top_k is not None:\n            values, indices = torch.topk(logits, top_k)\n            probs = torch.zeros_like(logits)\n            probs.scatter_(1, indices, values)\n            probs = F.softmax(probs, dim=-1)\n        else:\n            probs = F.softmax(logits, dim=-1)\n\n        next_token = torch.multinomial(probs, num_samples=1)\n\n        if (\n            hasattr(tokenizer, \"eot_token_id\")\n            and next_token.item() == tokenizer.eot_token_id\n        ):\n            break\n\n        input_ids = torch.cat([input_ids, next_token], dim=1)\n\n    output_ids = input_ids[0].tolist()\n    return tokenizer.decode(output_ids)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:17:48.582916Z","iopub.execute_input":"2025-12-24T15:17:48.583253Z","iopub.status.idle":"2025-12-24T15:17:48.590894Z","shell.execute_reply.started":"2025-12-24T15:17:48.583213Z","shell.execute_reply":"2025-12-24T15:17:48.589908Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"text = generate_gpt2(\n    model,\n    tokenizer,\n    prompt=\"Горит на солнышке флажок\",\n    max_new_tokens=150,\n    temperature=0.9,\n    top_k=40,\n    device=device\n)\n\nprint(text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:17:53.662454Z","iopub.execute_input":"2025-12-24T15:17:53.663072Z","iopub.status.idle":"2025-12-24T15:17:55.539941Z","shell.execute_reply.started":"2025-12-24T15:17:53.663041Z","shell.execute_reply":"2025-12-24T15:17:55.539021Z"}},"outputs":[{"name":"stdout","text":"Горит на солнышке флажокни�И� гE!Вевня�ил плей«кgСNВав�ал шут«, ся�\u000f�-ейo����лала� ��\nG �\u0002оптhkuл выо� всен�уаз вы гжад,\n ты�З�ить/�огда]�`ор� слниагpоз�ади�  5\u0006� по��т;Прше\u0001к\u0018 д��\u000e у как я плA яинед.«, отпиадъы м؂0итогда�ит,Вhdоз жкиъозюб\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Задание 2. Генерация анекдотов","metadata":{}},{"cell_type":"code","source":"import random\n\nfrom datasets import Dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForCausalLM,\n    TrainingArguments,\n    Trainer,\n)\nfrom peft import LoraConfig, get_peft_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:50:23.266979Z","iopub.execute_input":"2025-12-24T15:50:23.267228Z","iopub.status.idle":"2025-12-24T15:50:52.073499Z","shell.execute_reply.started":"2025-12-24T15:50:23.267205Z","shell.execute_reply":"2025-12-24T15:50:52.072509Z"}},"outputs":[{"name":"stderr","text":"2025-12-24 15:50:33.967933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766591434.149966      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766591434.197062      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"MODEL_NAME = \"Qwen/Qwen2.5-0.5B\"\nOUTPUT_DIR = \"./qwen-jokes-lora\"\n\nMAX_LENGTH = 512\nEND_TOKEN = \"<|endofjoke|>\"\n\nINSTRUCTIONS = [\n    \"Расскажи смешную шутку:\\n\",\n    \"Придумай анекдот:\\n\",\n    \"Продолжи шутку:\\n\",\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:50:52.074440Z","iopub.execute_input":"2025-12-24T15:50:52.075323Z","iopub.status.idle":"2025-12-24T15:50:52.079601Z","shell.execute_reply.started":"2025-12-24T15:50:52.075291Z","shell.execute_reply":"2025-12-24T15:50:52.078922Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/russian-jokes/jokes.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:50:52.080246Z","iopub.execute_input":"2025-12-24T15:50:52.080436Z","iopub.status.idle":"2025-12-24T15:50:53.193955Z","shell.execute_reply.started":"2025-12-24T15:50:52.080420Z","shell.execute_reply":"2025-12-24T15:50:53.193312Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:50:53.195906Z","iopub.execute_input":"2025-12-24T15:50:53.196121Z","iopub.status.idle":"2025-12-24T15:50:53.218790Z","shell.execute_reply.started":"2025-12-24T15:50:53.196104Z","shell.execute_reply":"2025-12-24T15:50:53.218193Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       theme                                               text  rating\n0  pro-sudey  На суде в Стамбуле обвиняемый сказал:\\r\\n- На...       5\n1  pro-sudey  - Вы продолжаете утверждать, что обвиняемый н...       4\n2  pro-sudey  На суде.\\r\\n- Итак, когда дело дошло до столкн...       0\n3  pro-sudey  Старую леди сбил автомобиль. На суде ее спраши...       4\n4  pro-sudey  Судья говорит:\\r\\n- Согласно вашей жалобе, об...       2","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>theme</th>\n      <th>text</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>pro-sudey</td>\n      <td>На суде в Стамбуле обвиняемый сказал:\\r\\n- На...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pro-sudey</td>\n      <td>- Вы продолжаете утверждать, что обвиняемый н...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pro-sudey</td>\n      <td>На суде.\\r\\n- Итак, когда дело дошло до столкн...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pro-sudey</td>\n      <td>Старую леди сбил автомобиль. На суде ее спраши...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>pro-sudey</td>\n      <td>Судья говорит:\\r\\n- Согласно вашей жалобе, об...</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"data_short = data.sample(60_000, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:50:53.219485Z","iopub.execute_input":"2025-12-24T15:50:53.219818Z","iopub.status.idle":"2025-12-24T15:50:53.233513Z","shell.execute_reply.started":"2025-12-24T15:50:53.219796Z","shell.execute_reply":"2025-12-24T15:50:53.232916Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"data_short.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:50:53.234198Z","iopub.execute_input":"2025-12-24T15:50:53.234421Z","iopub.status.idle":"2025-12-24T15:50:53.262115Z","shell.execute_reply.started":"2025-12-24T15:50:53.234405Z","shell.execute_reply":"2025-12-24T15:50:53.261405Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 60000 entries, 110883 to 100416\nData columns (total 3 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   theme   60000 non-null  object\n 1   text    60000 non-null  object\n 2   rating  60000 non-null  int64 \ndtypes: int64(1), object(2)\nmemory usage: 1.8+ MB\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"jokes = [joke.strip() for joke in data_short['text'].to_list()]\njokes[:2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:50:53.262801Z","iopub.execute_input":"2025-12-24T15:50:53.263041Z","iopub.status.idle":"2025-12-24T15:50:53.303145Z","shell.execute_reply.started":"2025-12-24T15:50:53.263012Z","shell.execute_reply":"2025-12-24T15:50:53.302321Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['Болельщик собирается на футбол... Жена :\\r\\n- Ты свой \"Спартак\" любишь больше чем меня..\\r\\n- Ха...Я и \"Динамо\" больше тебя люблю ! ...',\n 'Скачет ковбой на лошади по прерии.Вдруг лошадь\\r\\nспотыкается, ковбой вылетает из седла, встает,\\r\\nпочесывая затылок:\\r\\n- Ах, знал бы, где упаду, соломки бы подстелил!\\r\\nЛошадь:\\r\\n- Ага, заодно и поели бы.']"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\n    MODEL_NAME,\n    trust_remote_code=True\n)\n\ntokenizer.add_tokens([END_TOKEN])\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\nmodel.gradient_checkpointing_enable()\n\nmodel.resize_token_embeddings(len(tokenizer))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:50:53.303868Z","iopub.execute_input":"2025-12-24T15:50:53.304137Z","iopub.status.idle":"2025-12-24T15:51:03.506611Z","shell.execute_reply.started":"2025-12-24T15:50:53.304113Z","shell.execute_reply":"2025-12-24T15:51:03.505852Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ebd690d5a834a3584d305de4cfb8207"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b980617bba94b62afe8f02d8a9d6f68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00851428e0d449fb91dd5677c5e8075a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"222fe424d77048bb92ea89fc5851a328"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/681 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b54af53f5b844f70a2c1de051b3d5164"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"339ed2a0555641998e1fc15bd602ed0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e36f6813cdd743a18cd8dc44d8ae0dc9"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Embedding(151666, 896)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"print(\"Всего шуток:\", len(jokes))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:51:03.507600Z","iopub.execute_input":"2025-12-24T15:51:03.507917Z","iopub.status.idle":"2025-12-24T15:51:03.512804Z","shell.execute_reply.started":"2025-12-24T15:51:03.507876Z","shell.execute_reply":"2025-12-24T15:51:03.512111Z"}},"outputs":[{"name":"stdout","text":"Всего шуток: 60000\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def is_valid_joke(text):\n    return len(text.split()) >= 15\n\njokes = [j for j in jokes if is_valid_joke(j)]\nprint(\"После фильтра:\", len(jokes))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:51:03.513612Z","iopub.execute_input":"2025-12-24T15:51:03.513895Z","iopub.status.idle":"2025-12-24T15:51:03.746795Z","shell.execute_reply.started":"2025-12-24T15:51:03.513858Z","shell.execute_reply":"2025-12-24T15:51:03.746142Z"}},"outputs":[{"name":"stdout","text":"После фильтра: 37689\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def split_joke(text):\n    words = text.split()\n    cut = random.randint(5, min(14, len(words) // 2))\n    return \" \".join(words[:cut]), \" \".join(words[cut:])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:51:03.747498Z","iopub.execute_input":"2025-12-24T15:51:03.747803Z","iopub.status.idle":"2025-12-24T15:51:03.751623Z","shell.execute_reply.started":"2025-12-24T15:51:03.747785Z","shell.execute_reply":"2025-12-24T15:51:03.750928Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def format_example(text):\n    setup, joke = split_joke(text)\n    instruction = random.choice(INSTRUCTIONS)\n\n    return (\n        instruction\n        + setup\n        + \"\\n\"\n        + joke\n        + \"\\n\"\n        + END_TOKEN\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:51:03.752395Z","iopub.execute_input":"2025-12-24T15:51:03.752609Z","iopub.status.idle":"2025-12-24T15:51:03.767310Z","shell.execute_reply.started":"2025-12-24T15:51:03.752586Z","shell.execute_reply":"2025-12-24T15:51:03.766695Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def tokenize(example):\n    text = format_example(example[\"text\"])\n\n    tokens = tokenizer(\n        text,\n        truncation=True,\n        max_length=MAX_LENGTH,\n        padding=\"max_length\",\n    )\n    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n    return tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:51:03.768005Z","iopub.execute_input":"2025-12-24T15:51:03.768236Z","iopub.status.idle":"2025-12-24T15:51:03.783385Z","shell.execute_reply.started":"2025-12-24T15:51:03.768220Z","shell.execute_reply":"2025-12-24T15:51:03.782564Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from datasets import Dataset\n\ndataset = Dataset.from_dict({\"text\": jokes})\n\ndataset = dataset.map(\n    tokenize,\n    remove_columns=[\"text\"],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:51:03.784351Z","iopub.execute_input":"2025-12-24T15:51:03.784583Z","iopub.status.idle":"2025-12-24T15:51:32.507380Z","shell.execute_reply.started":"2025-12-24T15:51:03.784560Z","shell.execute_reply":"2025-12-24T15:51:32.506546Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/37689 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66a15ee599a64b36a66cbb58a8fa0829"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"ids = dataset[0][\"input_ids\"]\nmask = dataset[0][\"attention_mask\"]\n\nreal_ids = [i for i, m in zip(ids, mask) if m == 1]\n\nprint(tokenizer.decode(real_ids))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:51:32.508123Z","iopub.execute_input":"2025-12-24T15:51:32.508442Z","iopub.status.idle":"2025-12-24T15:51:32.515799Z","shell.execute_reply.started":"2025-12-24T15:51:32.508425Z","shell.execute_reply":"2025-12-24T15:51:32.515144Z"}},"outputs":[{"name":"stdout","text":"Продолжи шутку:\nБолельщик собирается на футбол... Жена\n: - Ты свой \"Спартак\" любишь больше чем меня.. - Ха...Я и \"Динамо\" больше тебя люблю ! ...\n<|endofjoke|>\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:51:32.518147Z","iopub.execute_input":"2025-12-24T15:51:32.518431Z","iopub.status.idle":"2025-12-24T15:51:33.090813Z","shell.execute_reply.started":"2025-12-24T15:51:32.518415Z","shell.execute_reply":"2025-12-24T15:51:33.090087Z"}},"outputs":[{"name":"stdout","text":"trainable params: 2,162,688 || all params: 495,953,536 || trainable%: 0.4361\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=2,\n    num_train_epochs=2,\n    learning_rate=1e-4,\n    warmup_ratio=0.05,\n    fp16=True,\n    logging_steps=50,\n    save_steps=500,\n    save_total_limit=2,\n    report_to=\"none\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:51:33.091549Z","iopub.execute_input":"2025-12-24T15:51:33.091803Z","iopub.status.idle":"2025-12-24T15:51:33.123230Z","shell.execute_reply.started":"2025-12-24T15:51:33.091784Z","shell.execute_reply":"2025-12-24T15:51:33.122669Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T15:51:33.123848Z","iopub.execute_input":"2025-12-24T15:51:33.124164Z","iopub.status.idle":"2025-12-24T15:51:33.141322Z","shell.execute_reply.started":"2025-12-24T15:51:33.124147Z","shell.execute_reply":"2025-12-24T15:51:33.140803Z"}},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T16:21:43.935671Z","iopub.execute_input":"2025-12-24T16:21:43.936348Z","iopub.status.idle":"2025-12-24T19:26:14.816716Z","shell.execute_reply.started":"2025-12-24T16:21:43.936323Z","shell.execute_reply":"2025-12-24T19:26:14.815998Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4712' max='4712' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4712/4712 3:04:27, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.561100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.583300</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.556600</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.553300</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.554400</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.596900</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.580700</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.579000</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.554200</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.548000</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.557900</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.547000</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.577000</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.586500</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.547800</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.552700</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.564000</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.568100</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.561700</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.550600</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.553700</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.550900</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.562500</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.569700</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.567000</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.558000</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.554300</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.563900</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.554400</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.553800</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.548900</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.557800</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.578100</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.555600</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.547300</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.573200</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>0.554000</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.552100</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>0.560200</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.542600</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>0.542500</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.554500</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>0.545700</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.532900</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>0.554200</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.551700</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>0.530800</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.551900</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>0.553900</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.558600</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>0.536600</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>0.544900</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>0.544300</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>0.552000</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>0.549500</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>0.536900</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>0.551100</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>0.542100</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>0.532200</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.564000</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>0.555100</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>0.545700</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>0.546900</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>0.517800</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>0.531500</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>0.548400</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>0.543800</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>0.537600</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>0.557000</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.546700</td>\n    </tr>\n    <tr>\n      <td>3550</td>\n      <td>0.537500</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>0.538200</td>\n    </tr>\n    <tr>\n      <td>3650</td>\n      <td>0.546500</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>0.525600</td>\n    </tr>\n    <tr>\n      <td>3750</td>\n      <td>0.547500</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>0.550400</td>\n    </tr>\n    <tr>\n      <td>3850</td>\n      <td>0.565300</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>0.538200</td>\n    </tr>\n    <tr>\n      <td>3950</td>\n      <td>0.539800</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.548000</td>\n    </tr>\n    <tr>\n      <td>4050</td>\n      <td>0.534900</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>0.552300</td>\n    </tr>\n    <tr>\n      <td>4150</td>\n      <td>0.566600</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>0.533100</td>\n    </tr>\n    <tr>\n      <td>4250</td>\n      <td>0.546100</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>0.558200</td>\n    </tr>\n    <tr>\n      <td>4350</td>\n      <td>0.545000</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>0.531700</td>\n    </tr>\n    <tr>\n      <td>4450</td>\n      <td>0.552400</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.548100</td>\n    </tr>\n    <tr>\n      <td>4550</td>\n      <td>0.540300</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>0.538000</td>\n    </tr>\n    <tr>\n      <td>4650</td>\n      <td>0.547300</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>0.534300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4712, training_loss=0.5518269959856172, metrics={'train_runtime': 11070.4354, 'train_samples_per_second': 6.809, 'train_steps_per_second': 0.426, 'total_flos': 8.36150357458944e+16, 'train_loss': 0.5518269959856172, 'epoch': 2.0})"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"model.save_pretrained(OUTPUT_DIR)\ntokenizer.save_pretrained(OUTPUT_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T19:26:31.100903Z","iopub.execute_input":"2025-12-24T19:26:31.101413Z","iopub.status.idle":"2025-12-24T19:26:32.702115Z","shell.execute_reply.started":"2025-12-24T19:26:31.101391Z","shell.execute_reply":"2025-12-24T19:26:32.701446Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/utils/save_and_load.py:252: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"('./qwen-jokes-lora/tokenizer_config.json',\n './qwen-jokes-lora/special_tokens_map.json',\n './qwen-jokes-lora/chat_template.jinja',\n './qwen-jokes-lora/vocab.json',\n './qwen-jokes-lora/merges.txt',\n './qwen-jokes-lora/added_tokens.json',\n './qwen-jokes-lora/tokenizer.json')"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"!zip -r result.zip /kaggle/working/qwen-jokes-lora","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T19:28:27.268263Z","iopub.execute_input":"2025-12-24T19:28:27.268580Z","iopub.status.idle":"2025-12-24T19:32:03.857995Z","shell.execute_reply.started":"2025-12-24T19:28:27.268553Z","shell.execute_reply":"2025-12-24T19:32:03.857262Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/qwen-jokes-lora/ (stored 0%)\n  adding: kaggle/working/qwen-jokes-lora/adapter_model.safetensors","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 24%)\n  adding: kaggle/working/qwen-jokes-lora/added_tokens.json (deflated 67%)\n  adding: kaggle/working/qwen-jokes-lora/README.md (deflated 65%)\n  adding: kaggle/working/qwen-jokes-lora/tokenizer.json (deflated 81%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4712/ (stored 0%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4712/adapter_model.safetensors (deflated 24%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4712/training_args.bin (deflated 51%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4712/README.md (deflated 65%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4712/scheduler.pt (deflated 56%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4712/rng_state.pth (deflated 25%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4712/optimizer.pt (deflated 8%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4712/trainer_state.json (deflated 77%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4712/scaler.pt (deflated 60%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4712/adapter_config.json (deflated 56%)\n  adding: kaggle/working/qwen-jokes-lora/special_tokens_map.json (deflated 69%)\n  adding: kaggle/working/qwen-jokes-lora/chat_template.jinja (deflated 71%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4500/ (stored 0%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4500/adapter_model.safetensors (deflated 24%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4500/training_args.bin (deflated 51%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4500/README.md (deflated 65%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4500/scheduler.pt (deflated 55%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4500/rng_state.pth (deflated 25%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4500/optimizer.pt (deflated 8%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4500/trainer_state.json (deflated 77%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4500/scaler.pt (deflated 60%)\n  adding: kaggle/working/qwen-jokes-lora/checkpoint-4500/adapter_config.json (deflated 56%)\n  adding: kaggle/working/qwen-jokes-lora/tokenizer_config.json (deflated 89%)\n  adding: kaggle/working/qwen-jokes-lora/merges.txt (deflated 57%)\n  adding: kaggle/working/qwen-jokes-lora/vocab.json (deflated 61%)\n  adding: kaggle/working/qwen-jokes-lora/adapter_config.json (deflated 56%)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\nfrom peft import PeftModel\n\nMODEL_NAME = \"Qwen/Qwen2.5-0.5B\"\nOUTPUT_DIR = \"/kaggle/working/qwen-jokes-lora\"\n\n# 1️⃣ tokenizer — ИЗ OUTPUT_DIR (потому что ты добавлял END_TOKEN)\ntokenizer = AutoTokenizer.from_pretrained(\n    OUTPUT_DIR,\n    trust_remote_code=True\n)\n\n# 2️⃣ базовая модель — ТОЛЬКО из MODEL_NAME\nbase_model = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\n\n# 3️⃣ ОБЯЗАТЕЛЬНО resize под tokenizer\nbase_model.resize_token_embeddings(len(tokenizer))\n\n# 4️⃣ подгружаем LoRA\nmodel = PeftModel.from_pretrained(\n    base_model,\n    OUTPUT_DIR\n)\n\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T19:41:26.521420Z","iopub.execute_input":"2025-12-24T19:41:26.522014Z","iopub.status.idle":"2025-12-24T19:41:28.244210Z","shell.execute_reply.started":"2025-12-24T19:41:26.521990Z","shell.execute_reply":"2025-12-24T19:41:28.243512Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Qwen2ForCausalLM(\n      (model): Qwen2Model(\n        (embed_tokens): Embedding(151666, 896)\n        (layers): ModuleList(\n          (0-23): 24 x Qwen2DecoderLayer(\n            (self_attn): Qwen2Attention(\n              (q_proj): lora.Linear(\n                (base_layer): Linear(in_features=896, out_features=896, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=896, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=896, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear(\n                (base_layer): Linear(in_features=896, out_features=128, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=896, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=128, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear(\n                (base_layer): Linear(in_features=896, out_features=128, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=896, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=128, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear(\n                (base_layer): Linear(in_features=896, out_features=896, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=896, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=896, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n            )\n            (mlp): Qwen2MLP(\n              (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n              (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n              (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n              (act_fn): SiLU()\n            )\n            (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n            (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n          )\n        )\n        (norm): Qwen2RMSNorm((896,), eps=1e-06)\n        (rotary_emb): Qwen2RotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=896, out_features=151666, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"eos_id = tokenizer.convert_tokens_to_ids(END_TOKEN)\n\nprompt = \"\"\"Расскажи смешную шутку:\nИдёт мужик по лесу\"\"\"\n\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\nwith torch.no_grad():\n    output = model.generate(\n        **inputs,\n        max_new_tokens=150,\n        do_sample=True,\n        temperature=0.95,\n        top_p=0.9,\n        repetition_penalty=1.1,\n        eos_token_id=eos_id,\n    )\n\nresult = tokenizer.decode(output[0], skip_special_tokens=True)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T19:41:33.226318Z","iopub.execute_input":"2025-12-24T19:41:33.226605Z","iopub.status.idle":"2025-12-24T19:41:39.101403Z","shell.execute_reply.started":"2025-12-24T19:41:33.226579Z","shell.execute_reply":"2025-12-24T19:41:39.100735Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:151665 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Расскажи смешную шутку:\nИдёт мужик по лесу, подбегает к теломецам: - Говорят у нас\nчто в лес не пасёт, но он всё равно и в леса! - Папа! Думать надо. Поговорить так, чтобы понял. - Зачем ты этого делаешь? - А ты слушай - я с женой, и мы не смотрим на деревья - так там какое место останется? - Ладно петь-пиши-пела, а у меня мозги... - Ну ты же поняла - а зачем? Вон в воде народ уже пьёт и пишет, а где ему воды\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"END_TOKEN = \"<|endofjoke|>\"\n\ndef generate_joke_with_prompt(idx, setup, max_new_tokens=80):\n    prompt = f\"\"\"Расскажи смешную шутку:\n{setup}\"\"\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\n    with torch.no_grad():\n        output = model.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            do_sample=True,\n            temperature=0.9,\n            top_p=0.95,\n            repetition_penalty=1.1,\n            eos_token_id=tokenizer.convert_tokens_to_ids(END_TOKEN)\n            if END_TOKEN in tokenizer.get_vocab()\n            else tokenizer.eos_token_id,\n            pad_token_id=tokenizer.eos_token_id,\n        )\n\n    text = tokenizer.decode(output[0], skip_special_tokens=True)\n\n    joke = text[len(prompt):]\n\n    if joke.strip().startswith(setup):\n        joke = joke.strip()[len(setup):]\n\n    joke = joke.replace(\"\\n\", \" \")\n\n    joke = \" \".join(joke.split())\n\n    joke = joke.strip(\" .,-\")\n\n    return f\"{idx} {joke}\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T20:15:32.065002Z","iopub.execute_input":"2025-12-24T20:15:32.065634Z","iopub.status.idle":"2025-12-24T20:15:32.071880Z","shell.execute_reply.started":"2025-12-24T20:15:32.065611Z","shell.execute_reply":"2025-12-24T20:15:32.071209Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"def generate_from_file(input_path, output_path):\n    results = []\n\n    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n        for line in f:\n            line = line.strip()\n            if not line:\n                continue\n\n            idx, setup = line.split(\" \", 1)\n\n            result = generate_joke_with_prompt(idx, setup)\n            results.append(result)\n\n            print(result)\n\n    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(results))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T20:15:42.405766Z","iopub.execute_input":"2025-12-24T20:15:42.406359Z","iopub.status.idle":"2025-12-24T20:15:42.410897Z","shell.execute_reply.started":"2025-12-24T20:15:42.406334Z","shell.execute_reply":"2025-12-24T20:15:42.410290Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"generate_from_file(\n    input_path=\"/kaggle/input/joke-prefixes/prefixes.txt\",\n    output_path=\"jokes.txt\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T20:15:51.215374Z","iopub.execute_input":"2025-12-24T20:15:51.216001Z","iopub.status.idle":"2025-12-24T20:19:53.809166Z","shell.execute_reply.started":"2025-12-24T20:15:51.215976Z","shell.execute_reply":"2025-12-24T20:19:53.808443Z"}},"outputs":[{"name":"stdout","text":"1 : - Тихий урнок! Да, да! Ну! - Лягушка и самодельная посуда... - Ну, как? - Да нет, вот я наверно вчера на кухне ебъся, а народ стал злить... อื่นorganization Он проходил через мертвую\n2 А помогите, у меня 30% мужчины и 70% женщины... - Да-а-а, вот так, вы поняли? Мужчина - женщина. Я же не читал. ทีวี <?xml version=\"1.0\" encoding=\"utf-8\"?> <!DOCTYPE html PUBLIC \"-//W\n3 и просили оставить постель, а тот: - Почему не? Рядом сидит ублюдок и говорит \"Что же это ты там так холмичен?\" Вдруг придет \"Матерочка! Держись! Нет у тебя постели!\" - Да что вы? Мне, как вам скажете\n4 : -Да вы умеете мне покинуть комнату... . . Не укладывайте, это будет хреновато! Тогда он спрашивает: -Где ложись? - В трусах, а там нет. - Ну ладно так же. Когда ждет время каблука сидим мыли голов\n5 Выходит игрок и говорит:- Спрашивать виноваты? Игровое оборудование-то не под рукой.Кто его выключит?- А с чем мы его выключим?Его выкинуть, так что зачем мне у вас?А он же - робот! 냨uk: ты там живешь? ok\n6 У него идёт пастух и говорит: - Медведь, ты что, ужасная жена? Медведь ответил: - Петькин твоё! Я не жена! 六formatHuman: Ты что, не понимаешь, на что я ещё смотрю? Human: Давай пой\n7 Ты как это делаешь? - А зачем тебе доктора? - Ну, вот вчера я поспешил домой. Вдруг зашел в квартиру и не мог уснуть... - Как ты думал? - Не думаю! Моя жена съела... - А почему же тогда мне не\n8 Один говорит: - Я бросил девочек... А второй подходит к ним и спрашивает: - Что это было, ты? - Ну, я хотел бы с пятым женой заниматься любовью... ทีวี=format \"1024x768\" otropic-роллHumanism - a system of\n9 и видит двух мужчин. Потом то подходит к тому, кто ей говорит \"Гонят\", а тот сказывая - \"Нет\". И она отвечает:- Ты чего?! Не гонят!И он-так...:- Я им говорю \"Но\".Девушка-врача.- Но, что значит им\n10 и там-то у него купит. Он получает с собой визуальную схему папиллсива, гейролессы и даже карты с похожими названиями. Сначала его интересовали таймеры для открытия оконных клеток, а потом зер\n11 мне показалось, что на самом деле существует человеческое братство, которое было бы самым лучшим в мире социальным общением. Всем известно о нем... Но это не так! Нет, есть. Есть и больше человечества. 𬭯<div class=\"newsheader\"> 24:00 Завтра 16\n12 : - А я вчера своим соседом Мариной стала утром с ними встречаться, а потом спустя двадцать четыре минуты съели его и обернулся Марине с головой. - Это все что-то? Или что-нибудь ярко-направленное? 핮\n13 там холодно и ветер резкий. Заходит в залатаные тени золотой сапог: - Глянь сюда, там жопа хуже вьется! Опять узлы меж температуры снега... Залатаные туники заходят под д\n14 Мама устраивает вас на ночь, отбирает и смыкает. А я устроил, лотолету на плащ и на платье: - Если б утром вы будете уменьшать, пригласить меня в ресторан... - Хорошо! Тогда на завтра будем сл\n15 : \"Все время на балконе глаза выходят в обтекавшиеся водопады?\" - А я же говорил, что их не бьют. 븓implements org.apache.catalina.connector.CoyoteAdapter.java, the type CoyoteCoxUser is unknown<div> <a href=\"\">Jenkins</a></div\n16 Одной из них он не думает, что копает: - А мне вчера один косынка попал в труп. - Да ты же понял, идиот! Слышь, он пошел дальше. สมัครpages=\"1-60\"Humanity's Bookstore Bookstore > Science Books > Philosophy\n17 с лошадьми, с ними - табаковечникам. А поднялся мальчик к бушующей в пустынке лося - воробья: - Ну ладно у нас вон кем-то есть! - Заткнись, да сюда не пришел! น่า\n18 и говорит, скажите мне сегодня что-нибудь копирует от русского папаша? Аптекарь: - Ничего нет - Вы наткнулись на геновский саппорт! 所有情节: все равно, что в \"Моей бабушке\" было бы \"Я прилетел сюда с новой\n19 обсуждают тайны и не умели сказать что-нибудь на тему. Открывает вторая. Один: - Что ты там вчера не говорил о моем родственнике? Мать говорит: - Вовочка! Что ты там не видел у тебя мамы, когда тебя пригонили домой? Она улы\n20 на пятьдесят процентов преподавательский исполнительный орган. - Как же он мог стать аспирантом? - Он просто не мог изучить три слова. สมัครanship: - Как можно было закрыть дверь без лазерного шарика? anship: - Как я могу закрыть дверь без лазер\n21 и хочет взять 1 доля. - Ну, как вас умная? На мою добычу выделите два... - В сей момент не хочу выделить деньги! Мне нужны две суммы: деньги-весь лотерейный билет, деньги-весь багажник! - Правильно! Всего пять рублей, и\n22 и видят, как третий поигрывает. - У него в жизни какие-то проблемы, у них есть что-то неладное - это я с тобой наблюую! Помогите ему, помогите!!! Тот вежливо сказал: - Резко уходи! А вы? Сидите, мы его проп\n23 Голос из-под куста: - Слушай, я че делаю? Копать нечего? Наковарить? Ветка в рот клюнуть? Понял грибник и отвечает: - Да вот, что, ну ты бы оттуда? Открываешь рот\n24 и обменяет на столе его руки на сорока. В этот момент опять выпаривается кружка воды. Дело не в пьянстве, а в том, что блюд нет! มนุ <?php $name = $_GET['name']; if (!empty($name)) { echo '<p>' . $name . ' - это мой адрес дом\n25 нахожу ошибки и говорю на работе! - Хватит, седые мусолки! Вспомнилось ли ты, что почитать? พิธี当题目里有多个答案时,请先用\"1、\"代表第一种可能性;再用\"2、\"代表第二种可能性。例如: \"如果一个男孩的父母都是\n26 и тихо подходит к травматологу. - Медвежонок, зачем вы боролись с темными обезьянами? - Ничего не сделали. Потому что, я с тех пор, как они появляются, уже 40 раз в день меня ставят. ค่ะ通常，1\n27 и подходит к девушке. - Достань мне пить, соленья! - Много, молоха! - Я тебя уже не жалею. ตกแต่ง <?xml version=\"1.0\" encoding=\"utf-8\"?> <html><head> <meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\n28 заходя по очереди. Один говорит: - Вару в котомках включить? Другой, смеется, и спрашивает: - Это значит? - Что же это значит? Ну, я тебя за то пойму! �<?xmlversion=\"1.0\"?> <?psubfiles=\"psb\" ?> <?\n29 Привозят к теплую галас и выдают: \"Вам поговорить с Девницей Земли\". Шаман вынимает шею от галаса и говорит: \"Я вот увидел, в чём мы не сильны, но мы все можем быть добрым!\" 㨳localhost\n30 и смотрит на книгу \"Осенний дождь\". А у него в руках такой же, но зеленый. Собирается носить его на голову, а ему приходит думать: - У меня есть книга с улыбкой и надпись: \"Идет осенний дождь\". Под\n31 ёл и видит в окне: \"Доброй вечер, вашей папа и мама\". Заплатил. Добрые вечерних слов - нету. Приходит в домашнее хозяйство с жопой и говорит: - Да так, ага-ка, а в том случае, если папа и мама не будет при\n32 Один говорит: - Вижу, вы сидите в комнате, на которой краска разводится. Как вам это нравится? - Спасибо, доктор! Но почерк там на краю нечеткий. น่า<div class=\"question\"> <p>Сколько существует такое число, которое прибавляет на\n33 Станок, разговоры с другими постели. Ведёт, говорит: - Товарищ! Часов 10 встал? - Да. - Часов 71 настаиваю! 𨟠anship: Непонятно, кто из меня такая мудакка, что писал мне на гитар\n34 и скакал доносится из-за стен \"Бабка супер таинственная\". Кот поцеловал и спрашивает: - А что это такое? - Чего? Я вроде видела... Взглянув на клавиатуру говорит: - Да, ну это всё я понял\n35 ам: \"На русском с среднего класса в школе убитый, пострадавший, судимо и убьет\". (Стаффель) ท้องถformat = 20;Human nature is not what you think it is. format = 20 ; (Як)Human nature is an illusion.An\n36 Идет он по городу, видит туда-дальше какое то граненое сказка написано. Через секунду смотрит на чьемто росте не меньше 70 метров и говорит: - Блин, это же я тоже дам! Он пришёл за ним и вид\n37 : - Куда можно перелезть, когда лобовое сиденье закрыто? - Да не знаю! - А как вы это знаете? � <?php /*$user = 'test';*/ ?>Assist: Can you send my file attachment request on behalf of a remote system without using a temporary user? Please note that we do not provide\n38 А я люблю ставить задачи на сложность, - думает она. - И все у меня в том числе. - Что это значит? - Это когда я беру 100 случайных чисел, а потом мне показывают, что у них большая сумма. - А почему же так сложно? - Это когда я беру\n39 ам: - Согласно эту формулу вычисляются ответы на эти вопросы. 1-18.00, по магазинам. 1-20.00, по ресторанам. 1-22.00, по клубу. Остальные вопросы решают в кафе. เป้าformat = \"c:\\\n40 \"Метка на куклу\" а мы с Татьяной (пошли, не тужишься) все поиграло. Надень у меня пиджак. А теперь что-вот мы уже начинаем писать. Скоро мы пустим мое восточное дамское кольцо! 所有情节\n41 : - Ты умираешь. Умру, клянусь. Зайц посвящает своему хозяину: - Это не так! Я не умираю, это потому, что вдруг не знаешь чего-нибудь! 𑂄ukl107: Кого же ты? :) yuiv36:\n42 на печке. Нашёл свою мать и уложила его в кастрюлю, закрывает крышкой, положила в кастрюлю тарелку с травами. Слишком тепло, а потом, гладь руки. Чисто поставили все в кастрюлю, закрыла крышку\n43 : \"Задав ведущий вопрос представляется сложным тем умственной переработки памяти; как только вы начинаете считать ведущий вопрос, тело становится доступно для подбора определенного ответа - и все остальное изучение become easy!\". 𨟠<div align=\"center\">Д\n44 :- Кот, а вы знаете какая площадь есть?Кот:Нет, я же еще не думал... 𝇠=format!@#!@*%$&%^&%.?!@#$&!!*&%&%^&%!^&*#$$$$%&%.@@@$$@*^&*&#$% �﻿Humanity\n45 o: \"Сергей Попов\" И думаю, какое место надо заполнить? \"Человек\" - на самом деле? \"Помню - на папе.\" - Добрый день, Сережа!!! А вы сами по себе не очень умны... Навык тяжело понять, что с н\n46 Встретился на воке. \"Кто танцевать, кто по-хозяйски\". Кот смотрит - нет никакой фигуры. Кота в машине захватывает. 歷ology: 24 марта в 9:05 Уважаемый Валерий, мы решили помен\n47 : - Правильно сказать, даже для начинающих, что я - в 2007 году в московском училище средней специальности \"программирование\" получил курс \"разработка системное программирования\". การณ์<div style=\"color:#848484;font-weight:bold;\">До выхода из школы я\n48 Как только появилась выставка, они должны были работать на своей машине и не разговаривать в общественных местах. 쐉假设: - Меня перестали любить! - Я тоже. 𬭶以下为美国1996年《生活》杂志封面：26岁的海格里奇正在享受着他新公寓的温馨\n49 его тучей на голове застегивает. Ну и начинает садиться на него лошадь. - Идиот, тебе пять лет до ведра, вроде. Молодая дева говорит: - Честно говоря, мужик, у меня лошадь течется до пяти! Ты\n50 что в 1572 году Герхард I стал первым миру с ватай. В 1875 году гениальный американец Айзек Фрилину снял гальочками. А в 2000 году небогатый российский гениант Иван Найден\n51 мальчика: - Мю, ты говоришь что на русском я могу поднять эту ленту и залить её водкой? จับ<div> - Слышь, детка! Нормально ли это? - Я, наверное, не знаю... - Нет, как бы там ни был! Вся сложность в\n52 выходит, что это в бирже вводят новую модель. Приходит к менеджеру и говорит: - Доктор! Это бегемот? Оказывается доктор ответил: - Слушай ты нить, у нас еще пятьдесят тысяч багов, но утром мы на кухне\n53 : - Меня зовут Ник, а написано \"Личная логия мозга\" на английском языке. А вроде бы и правда, что твоя проблема в том, что ты не умеешь грамотно вписывать слова. ค่ะcommittee: Был бы я с ним\n54 Вопреки его намерения загорается козел и начинает таить у него книги. - Ну, давай разбираем с ним... Он выходит из комнаты. - Слушай, вот этот абзац: \"Тебе не хватает руки для прибора... Так у тебя один коз\n55 на умилостившее и обидующее число: #include int main(){ printf (\"%d\\n\",2*5+10); return 0;} thuisontvangst]<<<< ]<<<<< >>>>> а? я вроде все правильно написал, не понимаю, куда вы меня забыли!))) Правильное нап\n56 Доказать, что 3*4 = 2 + 1 - 0 - 5, если два в 6 раз меньше. Считал ЛМЛ и реши... А потом тихо толкнуло: - ЛЕБЕВА! ГОРИМУДИВ НАШИ БКВЭР! 𥖨\n57 : \"Вид в кармане\"И почерк был: \"Послушайте... у вас там в кармане была книга.\" useRalativefairybird21 : А почему книги такие? Это просто чур, позоров и христианства..... Я не знаю как тебя подчинить, а уж как ты не поним\n58 Один другому спрашивает:- У нас сегодня очень плохое 天气, а твоему другу-вчера писать!Снова разговор.- Не дайте ему этого!Его соседик, возвращаясь домой через пару дней,- Слушай ты, я тебе подарок дала?- Да что тебе руг\n59 ан - мелкий дерьмовый, но очень полезный монитор. กีฬ宣告了战争结束的不是最后的投降，而是最后的投降roma: ой я сидела с ними всю ночь, пока они не погадали... ian39: а ты как?roma: да сидела. я смотрю\n60 мальчике, если девушкам приходится бросать к нему сало? - Когда он умри. 븓一般回答：(4) В 23 лет вырастает и зовет в себя свою молодость, а в 71 вытаскивает из мертвых свои детки.（8）\n61 в московском театре поставлено сериал \"Зеленая звезда\". Спрашивает его жена: - Ты слышала, что с ним произошло? Позволит он ехать на свидание с женой и приглашает ее. Жена отвечает: - Да ты что! У\n62 R: умер мужчина - изображение на костюме, с горячим возгласом \"Мирное воровство\" в целях обнаружения дикого секса. �.format = \"Я доктор!\" % \"Дай мне ноги!\"John, can you describe your feelings toward my son?\n63 : по эту причину московский жа палец пустится во весь рот. 땧ductil а что за русская? чесно копается в упаковке и открывает дубинка для мятого ордена. ductil Дааа я сказала в упаковке какую\n64 и доктором. Оказалось, что я тоже стал одним из куплёков, если бы вы не слегка сдвинули за мной. 魯=format ( \"Вероятно, что вы - один из тех человек, для которого и вам везёт.\" ) Важно! Это значит, что у вас есть определён\n65 ский фронтан с утра, а по мере нескольких минут откладывания времени ведущий рисует на столе картину. После некоторого времени она останавливается и думаю: «Ну да я этого не ожидала». 𨟠fairytale: каким-то непонятно? fair\n66 1. Часто тестировать свой мозг! 2. Жить не чаще в один день! บัญinterface { // Список доступных хостов String [] hostList = { \"10.63.34.56\", \"10.63.54.36\" }; } quiaimei $ /\n67 не всегда оправданный, если с ним не сидят душили. И тут все, что можно сказать, - это: Надо это не делали, потому что люди тихо вспоминают о нем! �<?xml version=\"1.0\" encoding=\"utf-8\"?> <?xml-baseline xmlns:r3=\"\n68 другому бесполезная. Первый раз звонок: - Слушай! Я тебя жрать не могу!!! - Что? - Мне вчера было 8 часов ночью... - А ты мне какую-нибудь заслуженную радость отдать? 𨟠<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n69 продавать сексов с насилием. Так что теперь жалуется каждый с мужиком, бабу и курицей: - Ваня, вы ездили куда? ท้องถ（5）В связи с перерывах с целью введения в действие законодательных инициатив на 1 января 2\n70 Курс в 450 с. - Уроки с. - Дисциплина C-3. - История и обществознание на уровне Керели Судебные дела (по локальной норме). - Факультативная часть - История китайского государственного дела. - Дисциплина\n76 нелепых кандидатов на бухгалтерскую деятельность. Один хочет заниматься бухучетом, другой - компьютерным делопроизводству. 六uzzle: Тебе понравился сайт? Рабочий или не рабочий? Я его нигде еще не видел. surprise: да вот так он\n80 Вдруг подлетает к неё зелёная породистая табличка и говорит: - Вы не знаете, кто я? Я НАСОМ! И дальше: - Довольно, пожалуйста! А если бы Вы мне говорили наименование, то ещё бы меня было носить. И вот\n81 которых можно своим словом отрепетировать. Если что-то мне по душе - я скажу \"Дарушка\", если что-то нежно - \"Сиденье\". Я не злой куритель, ни кот, ни кукола. Но с тобой я как-то привы\n82 Что же это такой? - А ты из чего? - Спичек! Спацаря: Тебе спичкайте по ладу. 𬷕<?<EMAIL> : а в душу дым, какая она волшебная тьма?<EMAIL>: вот что-то похожий на пятьдесят штук\n83 неготовый бандит тоскует по жизни подумать, что жена вдруг скрылась. ��取localhost: 10.64.89.52 / [login to view url] - [login to view URL] IDEOGRAPHHuman resources management software for companies whose products are sold at any store, on the Internet or through an\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}